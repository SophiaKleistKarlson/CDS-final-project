{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_preprocessing_script.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPtdfjfVG2fZCtynNCJ4fEX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SophiaKleistKarlson/CDS-final-project/blob/main/Image_preprocessing_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM-QTyulHg0T"
      },
      "source": [
        "**Preprocessing script for images**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1j64W0CJiWt"
      },
      "source": [
        "The images are first uploaded to google colaboratory as a zipfile. A .csv file created in the R preprocessing script is also uploaded, containing unique names for each image and their path. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Suayo52RI54P"
      },
      "source": [
        "# load necessary modules\n",
        "import glob\n",
        "import re\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# define path\n",
        "path = \"/content/\"\n",
        "os.chdir(path)\n",
        "    \n",
        "# create folder for all images to be put in\n",
        "if not os.path.exists('data'):\n",
        "    os.makedirs('data')\n",
        "\n",
        "# define new path where we will put the zip file with all images\n",
        "new_path = \"/content/data/\"\n",
        "os.chdir(new_path)\n",
        "print(new_path)\n",
        "    \n",
        "# import zipfile 'transmission_VY53sLXHyJ6H_0G5z021ZWZdA.zip' (containing all the images) into the data folder\n",
        "uploaded = files.upload()\n",
        "\n",
        "# also import 'Drawing_ID.csv' containing unique drawing names and paths\n",
        "uploaded = files.upload()\n",
        "\n",
        "# unzip the zipfile\n",
        "!unzip 'transmission_VY53sLXHyJ6H_0G5z021ZWZdA.zip' #\"my_archive.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px-9NSs8HrU_"
      },
      "source": [
        "Now, assign unique names to images using the Drawing_ID.csv file and put them all in one folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-3RmWhtIHA8"
      },
      "source": [
        "# import the necessary packages\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# set path\n",
        "path = '/content/'\n",
        "os.chdir(path)\n",
        "\n",
        "# create folder for all images to be put in\n",
        "if not os.path.exists('all_drawings'):\n",
        "    os.makedirs('all_drawings')\n",
        "\n",
        "# Import the csv file with image paths and unique names\n",
        "Drawing_IDs = pd.read_csv('data/Drawing_IDs.csv')\n",
        "\n",
        "# make the image path column to a list\n",
        "image_path_list = Drawing_IDs[[\"image_path\"]]\n",
        "image_path_list = image_path_list[\"image_path\"].tolist()\n",
        "\n",
        "# make the image ID column to a list\n",
        "image_ID_list = Drawing_IDs[[\"Drawing_ID\"]]\n",
        "image_ID_list = image_ID_list[\"Drawing_ID\"].tolist()\n",
        "\n",
        "# Loop that reads the image paths and saves them into the all_drawings folder with their unique names\n",
        "for i in range(len(image_ID_list)):\n",
        "    drawing = cv2.imread(image_path_list[i])\n",
        "    drawing_ID = \"all_drawings/\" + image_ID_list[i] + \".png\"\n",
        "    cv2.imwrite(drawing_ID, drawing)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8vICtUmIgKj"
      },
      "source": [
        "All drawings are now resized to 400x400 px."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhMYunCrHX1y"
      },
      "source": [
        "# load necessary modules\n",
        "import cv2\n",
        "import glob\n",
        "import re\n",
        "import os\n",
        "\n",
        "\n",
        "# define path where all drawings are\n",
        "path = \"/content/\"\n",
        "os.chdir(path)\n",
        "print(path)\n",
        "\n",
        "# make a list of all the drawings\n",
        "img_list = glob.glob(path + \"all_drawings/*.png\")\n",
        "img_list.sort() # sort the list alphabetically\n",
        "\n",
        "print(len(img_list))\n",
        "\n",
        "# make empty list to be filled with filenames\n",
        "id = []\n",
        "\n",
        "# make folder for the resized images\n",
        "if not os.path.exists('resized'):#'all_resized_drawings'\n",
        "    os.makedirs('resized')\n",
        "\n",
        "# loop that resizes each image to 400x400 px\n",
        "for i in range(len(img_list)):\n",
        "  id.append(re.findall('/content/all_drawings/(Chain_\\d+_Gen_\\d+_Cond_\\d+_Source_\\d+).png', img_list[i])[0])\n",
        "  src = cv2.imread(img_list[i], cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "  # set a new height and width in pixels\n",
        "  new_height = 400\n",
        "  new_width = 400\n",
        "\n",
        "  # dsize\n",
        "  dsize = (new_width, new_height)\n",
        "\n",
        "  # resize image\n",
        "  output = cv2.resize(src, dsize)\n",
        "  \n",
        "  # write the resized image and put it in the all_resized_drawings folder\n",
        "  cv2.imwrite('/content/resized/{}.png'.format(id[i]), output) #'C:/Users/Sophia/Documents/Social Transmission Study/Analysis of drawings/data/all_drawings/all_resized_drawings/{}.png'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYlG3A-7Hf5N"
      },
      "source": [
        "The resized images are blurred using cv.blur(), using the convolution function, and then converted to jpeg2000 format. The unblurred images are also converted into jpeg2000 format. The file sizes these two batches of .jp2 images are calculated, put into a dataframe and saved as a csv. This csv as well as the resized images, blurred images and jpeg2000 files are zipped and downloaded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKwt8apyIwy7"
      },
      "source": [
        "# import the necessary packages\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "import cv2\n",
        "import cv2 as cv\n",
        "from google.colab import files\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# Define function that blurs images, converts them and the original into .jp2 format, reads filesizes and puts it all into a pandas dataframe\n",
        "def complexity_comparison_function(img_list):\n",
        "  \n",
        "  # make directory to put jp2 files\n",
        "  if not os.path.exists('jpeg_compressed_files_comparison'):\n",
        "    os.makedirs('jpeg_compressed_files_comparison')\n",
        "\n",
        "  # make directory to put blurred png files\n",
        "  if not os.path.exists('blurred_images'):\n",
        "    os.makedirs('blurred_images')\n",
        "    \n",
        "  # prepare dataframe\n",
        "  columns = ['Drawing_ID', 'Complexity_original', 'Complexity_convolution']\n",
        "  index = np.arange(0)\n",
        "  Complexity_comparison_data = pd.DataFrame(columns=columns, index = index)\n",
        "\n",
        "  # list for id's\n",
        "  id = []\n",
        "  \n",
        "  # convert png to jp2\n",
        "  for i in range(len(img_list)):\n",
        "    id.append(re.findall('/content/resized/(Chain_\\d+_Gen_\\d+_Cond_\\d+_Source_\\d+).png', img_list[i])[0]) \n",
        "    \n",
        "    #complexity of original:\n",
        "    img_original = Image.open(img_list[i])\n",
        "    img_original.convert(\"RGBA\").save(\"jpeg_compressed_files_comparison/Original_{}.jp2\".format(id[i]), 'JPEG2000', quality_mode='dB', quality_layers=[80])\n",
        "    \n",
        "    # read image for blurring\n",
        "    img_blur = cv.imread(img_list[i])\n",
        "\n",
        "    # convolution\n",
        "    kernel = np.ones((5,5),np.float32)/25\n",
        "    dst = cv.filter2D(img_blur,-1,kernel)\n",
        "    cv2.imwrite('/content/blurred_images/Convolution_{}.png'.format(id[i]), dst)\n",
        "\n",
        "    # jpeg2000 convertion of blurred images\n",
        "    img_convolution = Image.open(\"/content/blurred_images/Convolution_{}.png\".format(id[i]))\n",
        "    img_convolution.convert(\"RGBA\").save(\"jpeg_compressed_files_comparison/Convolution_{}.jp2\".format(id[i]), 'JPEG2000', quality_mode='dB', quality_layers=[80])\n",
        "\n",
        "  # list of original jp2 files\n",
        "  img_jp2_original = glob.glob(\"jpeg_compressed_files_comparison/Original_*.jp2\")\n",
        "  img_jp2_original.sort() #important! Else the IDs and complexity scores won't match\n",
        "\n",
        "  # list of convolution jp2 files\n",
        "  img_jp2_convolution = glob.glob(\"jpeg_compressed_files_comparison/Convolution_*.jp2\")\n",
        "  img_jp2_convolution.sort()\n",
        "\n",
        "  # save size and ID to dataframe\n",
        "  for i in range(len(img_jp2_original)): \n",
        "    size_original = (Path(img_jp2_original[i]).stat().st_size)\n",
        "    size_convolution = (Path(img_jp2_convolution[i]).stat().st_size)\n",
        "\n",
        "    Complexity_comparison_data = Complexity_comparison_data.append({\n",
        "      'Drawing_ID': id[i],\n",
        "      'Complexity_original': size_original, \n",
        "      'Complexity_convolution': size_convolution\n",
        "    }, ignore_index=True)\n",
        "\n",
        "  return Complexity_comparison_data\n",
        "\n",
        "\n",
        "# define path where all drawings are\n",
        "path = \"/content/resized/\" \n",
        "images = glob.glob(path + \"*.png\")\n",
        "print(len(images))\n",
        "images.sort() #important! Else the IDs and complexity scores won't match\n",
        "\n",
        "# run function on all drawings\n",
        "complexity_comparison_data = complexity_comparison_function(images)\n",
        "\n",
        "# print complexity scores and ID's\n",
        "print(complexity_comparison_data)\n",
        "\n",
        "# prepare logfilename and save\n",
        "logfilename = \"complexity_comparison.csv\"\n",
        "complexity_comparison_data.to_csv(logfilename)\n",
        "\n",
        "# prepare zipfile\n",
        "zipObj = ZipFile('image_processing.zip', 'w')\n",
        "\n",
        "# add complexity_comparison.csv to the zipfile\n",
        "zipObj.write('complexity_comparison.csv')\n",
        "\n",
        "# prepare lists of resized and blurred images and jp2 files\n",
        "resized = glob.glob('resized/' + \"*.png\")\n",
        "blurred = glob.glob('blurred_images/' + \"*.png\")\n",
        "jpeg2000 = glob.glob('jpeg_compressed_files_comparison/' + \"*.jp2\")\n",
        "\n",
        "# loop over the resized and blurred images and add them to the zipfile\n",
        "for i in range(len(blurred)):\n",
        "  # Add multiple files to the zipfile\n",
        "  zipObj.write(resized[i])\n",
        "  zipObj.write(blurred[i])\n",
        "\n",
        "# loop over the jp2 files and add them to the zipfile\n",
        "for i in range(len(jpeg2000)):\n",
        "  zipObj.write(jpeg2000[i])\n",
        "\n",
        "# close the zipfile\n",
        "zipObj.close()\n",
        "\n",
        "# download zipfile\n",
        "files.download(\"image_processing.zip\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPfxELrrDULa"
      },
      "source": [
        "Calculating complexity of resized source images:\n",
        "\n",
        "**NB:** First, I manually created a folder called \"resized_source\" and uploaded the 12 resized source images here.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE9DDEiCDX5Q"
      },
      "source": [
        "# import the necessary packages\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "import cv2\n",
        "import cv2 as cv\n",
        "from google.colab import files\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# Define function\n",
        "def complexity_comparison_function(img_list):\n",
        "  \n",
        "  # make directory to put jp2 files\n",
        "  if not os.path.exists('jpeg_compressed_files_comparison_source'):\n",
        "    os.makedirs('jpeg_compressed_files_comparison_source')\n",
        "\n",
        "  # make directory to put blurred png files\n",
        "  if not os.path.exists('blurred_source_images'):\n",
        "    os.makedirs('blurred_source_images')\n",
        "    \n",
        "  # prepare dataframe\n",
        "  columns = ['Drawing_ID', 'Complexity_original', 'Complexity_convolution']\n",
        "  index = np.arange(0)\n",
        "  Complexity_comparison_data = pd.DataFrame(columns=columns, index = index)\n",
        "\n",
        "  # list for id's\n",
        "  id = []\n",
        "  \n",
        "  # convert png to jp2\n",
        "  for i in range(len(img_list)):\n",
        "    id.append(re.findall('/content/resized_source/(stim_\\d+).png', img_list[i])[0]) \n",
        "    \n",
        "    #complexity of original:\n",
        "    img_original = Image.open(img_list[i])\n",
        "    img_original.convert(\"RGBA\").save(\"jpeg_compressed_files_comparison_source/Original_{}.jp2\".format(id[i]), 'JPEG2000', quality_mode='dB', quality_layers=[80])\n",
        "    \n",
        "    # read image for blurring\n",
        "    img_blur = cv.imread(img_list[i])\n",
        "\n",
        "    # convolution\n",
        "    kernel = np.ones((5,5),np.float32)/25\n",
        "    dst = cv.filter2D(img_blur,-1,kernel)\n",
        "    cv2.imwrite('/content/blurred_source_images/Convolution_{}.png'.format(id[i]), dst)\n",
        "\n",
        "    # jpeg2000 convertion of blurred images\n",
        "    img_convolution = Image.open(\"/content/blurred_source_images/Convolution_{}.png\".format(id[i]))\n",
        "    img_convolution.convert(\"RGBA\").save(\"jpeg_compressed_files_comparison_source/Convolution_{}.jp2\".format(id[i]), 'JPEG2000', quality_mode='dB', quality_layers=[80])\n",
        "\n",
        "  # list of original jp2 files\n",
        "  img_jp2_original = glob.glob(\"jpeg_compressed_files_comparison_source/Original_*.jp2\")\n",
        "  img_jp2_original.sort() #important! Else the IDs and complexity scores won't match\n",
        "\n",
        "  # list of convolution jp2 files\n",
        "  img_jp2_convolution = glob.glob(\"jpeg_compressed_files_comparison_source/Convolution_*.jp2\")\n",
        "  img_jp2_convolution.sort()\n",
        "\n",
        "  # save size and ID to dataframe\n",
        "  for i in range(len(img_jp2_original)): \n",
        "    size_original = (Path(img_jp2_original[i]).stat().st_size)\n",
        "    size_convolution = (Path(img_jp2_convolution[i]).stat().st_size)\n",
        "\n",
        "    Complexity_comparison_data = Complexity_comparison_data.append({\n",
        "      'Drawing_ID': id[i],\n",
        "      'Complexity_original': size_original, \n",
        "      'Complexity_convolution': size_convolution\n",
        "    }, ignore_index=True)\n",
        "\n",
        "  return Complexity_comparison_data\n",
        "\n",
        "\n",
        "# define path where all drawings are\n",
        "path = \"/content/resized_source/\" \n",
        "images = glob.glob(path + \"*.png\")\n",
        "print(len(images))\n",
        "images.sort() #important! Else the IDs and complexity scores won't match\n",
        "\n",
        "# run function on all drawings\n",
        "complexity_comparison_data = complexity_comparison_function(images)\n",
        "\n",
        "# print complexity scores and ID's\n",
        "print(complexity_comparison_data)\n",
        "\n",
        "# prepare logfilename and save\n",
        "logfilename = \"complexity_comparison_source.csv\"\n",
        "complexity_comparison_data.to_csv(logfilename)\n",
        "\n",
        "# prepare zipfile\n",
        "zipObj = ZipFile('source_image_processing.zip', 'w')\n",
        "\n",
        "# add complexity_comparison.csv to the zipfile\n",
        "zipObj.write('complexity_comparison_source.csv')\n",
        "\n",
        "# prepare lists of resized and blurred images and jp2 files\n",
        "resized = glob.glob('resized_source/' + \"*.png\")\n",
        "blurred = glob.glob('blurred_source_images/' + \"*.png\")\n",
        "jpeg2000 = glob.glob('jpeg_compressed_files_comparison_source/' + \"*.jp2\")\n",
        "\n",
        "# loop over the resized and blurred images and add them to the zipfile\n",
        "for i in range(len(blurred)):\n",
        "  # Add multiple files to the zipfile\n",
        "  zipObj.write(resized[i])\n",
        "  zipObj.write(blurred[i])\n",
        "\n",
        "# loop over the jp2 files and add them to the zipfile\n",
        "for i in range(len(jpeg2000)):\n",
        "  zipObj.write(jpeg2000[i])\n",
        "\n",
        "# close the zipfile\n",
        "zipObj.close()\n",
        "\n",
        "# download zipfile\n",
        "files.download(\"source_image_processing.zip\") "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}